{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "979ad769",
   "metadata": {},
   "source": [
    "# Business Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3fd3516",
   "metadata": {},
   "source": [
    "The business problem is a radiologist who wants to double-check their work with a model that classifies x-rays as Pneumonia or normal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9aad44e",
   "metadata": {},
   "source": [
    "# Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a0b042",
   "metadata": {},
   "source": [
    "The data consists of 5,856 chest x-ray images. Each image is labelled as either normal or pneumonia.  25% of the images are labelled normal and 75% pneumonia.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f47dd35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b49c226a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "945e9892",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=Path('./data/archive/chest_xray/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c5ff077",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import array_to_img, img_to_array, load_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b29a1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717d21cf",
   "metadata": {},
   "source": [
    "Loading and converting data to array format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c68a5d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#DONT RUN\n",
    "train_data_dir = i\n",
    "\n",
    "# Get all the data in the directory data/train, and reshape them\n",
    "train_generator = ImageDataGenerator().flow_from_directory(\n",
    "        train_data_dir, \n",
    "        target_size=(64, 64), batch_size=5216, color_mode = \"grayscale\")\n",
    "\n",
    "# Create the datasets\n",
    "train_images, train_labels = next(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f539ed1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5216, 64, 64, 1)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3c26c4f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#DONT RUN\n",
    "\n",
    "\n",
    "# Directory path\n",
    "val_data_dir = './data/archive/chest_xray/val'\n",
    "test_data_dir = './data/archive/chest_xray/test'\n",
    "\n",
    "# Get all the data in the directory data/train (790 images), and reshape them\n",
    "val_generator = ImageDataGenerator().flow_from_directory(\n",
    "        val_data_dir, \n",
    "        target_size=(64, 64), batch_size= 16, color_mode = \"grayscale\")\n",
    "\n",
    "# Get all the data in the directory data/validation (132 images), and reshape them\n",
    "test_generator = ImageDataGenerator().flow_from_directory(\n",
    "        test_data_dir, \n",
    "        target_size=(64, 64), batch_size=234+390, color_mode = \"grayscale\")\n",
    "\n",
    "\n",
    "# Create the datasets\n",
    "val_images, val_labels = next(val_generator)\n",
    "test_images, test_labels = next(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4d0728b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1583., 4273.], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(train_labels1)+ sum(test_labels1)+sum(val_labels1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6629464a",
   "metadata": {},
   "source": [
    "Training class distribution is 1583 to 4273, i.e. 27% and 73%, normal and pneumonia.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7581df4a",
   "metadata": {},
   "source": [
    "Pickling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94911bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e57b7e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_images.pickle', 'wb') as f:\n",
    "    pickle.dump(train_images, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc338a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7f6a5720",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_labels.pickle', 'wb') as f:\n",
    "    pickle.dump(train_labels, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d2b45cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_images.pickle', 'wb') as f:\n",
    "    pickle.dump(test_images, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "157ea59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_labels.pickle', 'wb') as f:\n",
    "    pickle.dump(test_labels, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e714122d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('val_images.pickle', 'wb') as f:\n",
    "    pickle.dump(val_images, f)\n",
    "\n",
    "    \n",
    "with open('val_labels.pickle', 'wb') as f:\n",
    "    pickle.dump(val_labels, f)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0ab18ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_images.pickle', 'rb') as g:\n",
    "    train_images2= pickle.load(g)\n",
    "with open('test_images.pickle', 'rb') as f:\n",
    "    test_images1= pickle.load(f)\n",
    "with open('val_images.pickle', 'rb') as f:\n",
    "    val_images1= pickle.load(f)\n",
    "    \n",
    "with open('train_labels.pickle', 'rb') as f:\n",
    "    train_labels1= pickle.load(f)\n",
    "with open('test_labels.pickle', 'rb') as f:\n",
    "    test_labels1= pickle.load(f)\n",
    "with open('val_labels.pickle', 'rb') as f:\n",
    "    val_labels1= pickle.load(f)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c70c0d",
   "metadata": {},
   "source": [
    "Combining data from files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfae61c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.append(train_images2, val_images1, axis=0)\n",
    "t1 = np.append(train_labels1, val_labels1, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d19e7d8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5856, 64, 64, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = np.append(t, test_images1, axis=0)\n",
    "t1 = np.append(t1, test_labels1, axis=0)\n",
    "np.shape(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f3916ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "979ef6aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5856, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "np.shape(t1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfea732",
   "metadata": {},
   "source": [
    "Splitting data into training, validation and test groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8d21b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, test_images, train_labels, test_labels = train_test_split(t, t1, random_state =5) \n",
    "train_images, val_images, train_labels, val_labels = train_test_split(train_images, train_labels, random_state =5) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bd78d5",
   "metadata": {},
   "source": [
    "Reshaping data for modelling purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47ce2685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1464, 4096)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images = np.reshape(test_images, (1464,64*64))\n",
    "np.shape(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "188f4346",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = np.reshape(train_images, (np.shape(train_images)[0],64*64))\n",
    "np.shape(train_images)\n",
    "\n",
    "val_images = np.reshape(val_images, (np.shape(val_images)[0],64*64))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f93439e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "780d7e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac1f0d9",
   "metadata": {},
   "source": [
    "Removing extra column from labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de40b18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels= train_labels[:,0]\n",
    "val_labels= val_labels[:,0]\n",
    "test_labels= test_labels[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00593294",
   "metadata": {},
   "source": [
    "Standardizing image data by diving by the maximum pixel value of 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6bad158e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images=train_images/255\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b334ad68",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_images=val_images/255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063cb0f7",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c889b3d5",
   "metadata": {},
   "source": [
    "Building initial model, a neural network with 1 hidden layer, with 64 neurons.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4d70db8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(64, input_shape = (4096,), activation = 'tanh'))\n",
    "model.add(tf.keras.layers.Dense(1, activation = 'sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ec1047c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'sgd', loss =  'mse', metrics = ['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0b437a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "52/52 [==============================] - 1s 7ms/step - loss: 0.1824 - acc: 0.7310 - val_loss: 0.1562 - val_acc: 0.7641\n",
      "Epoch 2/4\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.1526 - acc: 0.7872 - val_loss: 0.1348 - val_acc: 0.8097\n",
      "Epoch 3/4\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.1347 - acc: 0.8297 - val_loss: 0.1226 - val_acc: 0.8579\n",
      "Epoch 4/4\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.1234 - acc: 0.8503 - val_loss: 0.1306 - val_acc: 0.8579\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1cc33b36b80>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images,train_labels, batch_size=64, epochs=4, validation_data =(val_images,val_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "144c9567",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model.pickle', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5c4c3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7a6d539",
   "metadata": {},
   "source": [
    "Builing second model by adding an additional layer with 32 neurons and same tanh activation function.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "672e58e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = tf.keras.Sequential()\n",
    "model2.add(tf.keras.layers.Dense(64, input_shape = (4096,), activation = 'tanh'))\n",
    "model2.add(tf.keras.layers.Dense(32, activation = 'tanh'))\n",
    "model2.add(tf.keras.layers.Dense(1, activation = 'sigmoid'))\n",
    "#model.add(tf.keras.layers.Activation('relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "39151cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(optimizer = 'sgd', loss =  'mse', metrics = ['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "094710f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "52/52 [==============================] - 1s 7ms/step - loss: 0.1953 - acc: 0.7089 - val_loss: 0.1663 - val_acc: 0.7441\n",
      "Epoch 2/6\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.1638 - acc: 0.7544 - val_loss: 0.1453 - val_acc: 0.7942\n",
      "Epoch 3/6\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.1445 - acc: 0.8045 - val_loss: 0.1304 - val_acc: 0.8397\n",
      "Epoch 4/6\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.1303 - acc: 0.8345 - val_loss: 0.1387 - val_acc: 0.8452\n",
      "Epoch 5/6\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.1213 - acc: 0.8534 - val_loss: 0.1134 - val_acc: 0.8470\n",
      "Epoch 6/6\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.1121 - acc: 0.8652 - val_loss: 0.1159 - val_acc: 0.8698\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1a43b1903a0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(train_images,train_labels, batch_size=64, epochs=6, validation_data =(val_images,val_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c4875d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model2.pickle', 'wb') as f:\n",
    "    pickle.dump(model2, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ccafef0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model2.pickle', 'rb') as f:\n",
    "    model2= pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c7d654",
   "metadata": {},
   "source": [
    "Model 2 achieves a higher validation accuracy of 89% as opposed to baseline model's 85%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262e9951",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "257787ed",
   "metadata": {},
   "source": [
    "Building third model by increasing the learning rate of the optimizer from default .001 to .05 in order to try to reduce overfitting.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf5e1b8",
   "metadata": {},
   "source": [
    "Use same layers as model2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "767f7deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.SGD(learning_rate = .05)\n",
    "model3 = tf.keras.Sequential()\n",
    "model3.add(tf.keras.layers.Dense(64, input_shape = (4096,), activation = 'tanh'))\n",
    "model3.add(tf.keras.layers.Dense(32, activation = 'tanh'))\n",
    "model3.add(tf.keras.layers.Dense(1, activation = 'sigmoid'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ce118ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(optimizer = opt, loss =  'mse', metrics = ['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e023111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 0.2008 - acc: 0.7116 - val_loss: 0.1634 - val_acc: 0.7441\n",
      "Epoch 2/6\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.1751 - acc: 0.7505 - val_loss: 0.1518 - val_acc: 0.8561\n",
      "Epoch 3/6\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.1495 - acc: 0.7914 - val_loss: 0.1164 - val_acc: 0.8452\n",
      "Epoch 4/6\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.1311 - acc: 0.8209 - val_loss: 0.1030 - val_acc: 0.8670\n",
      "Epoch 5/6\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.1231 - acc: 0.8339 - val_loss: 0.1839 - val_acc: 0.7541\n",
      "Epoch 6/6\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.1081 - acc: 0.8616 - val_loss: 0.1273 - val_acc: 0.8215\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1a4318c8820>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(train_images,train_labels, batch_size=64, epochs=6, validation_data =(val_images,val_labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8a312d",
   "metadata": {},
   "source": [
    "Appears to be over-learning, minimum loss is overshot.  Model2 has best performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "edbbcd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model3.pickle', 'wb') as f:\n",
    "    pickle.dump(model3, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e39ee42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "with open('model3.pickle', 'rb') as f:\n",
    "    model3= pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "469c3456",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images=test_images/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f0261335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1071 - acc: 0.8805\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.10705896466970444, 0.880464494228363]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd708a5e",
   "metadata": {},
   "source": [
    "Accuracy on test set is 88%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f67b7be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "preds = model2.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fd53e0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat= []\n",
    "for i in preds:\n",
    "    if i<.5:\n",
    "        yhat.append(0)\n",
    "    else:\n",
    "        yhat.append(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "39493afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d04e6bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf = confusion_matrix(test_labels, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e9b65d56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[975, 105],\n",
       "       [ 70, 314]], dtype=int64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "82cd951c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a0e198b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1a431baa820>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cmd = ConfusionMatrixDisplay(cnf)\n",
    "cmd=cmd.from_predictions(test_labels, yhat)\n",
    "cmd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd94116b",
   "metadata": {},
   "source": [
    "105 false negatives 70 false positives out of 1464 predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a286cb",
   "metadata": {},
   "source": [
    "# Results/Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ed37f0",
   "metadata": {},
   "source": [
    "The 2nd model performed best based on the validation sets, higher accuracy than the baseline model and the faster learning model.  The chosen model's accuracy on the holdout test set was 88%.  This can be compared to guessing based on the sample balance, which would yield 73% accuracy.  Thus this model can be used as a check by the radiologist, for instance on x-rays that they are less certain about.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dash-env)",
   "language": "python",
   "name": "dash-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e48f613c",
   "metadata": {},
   "source": [
    "# Xray classification\n",
    "Jonathan Marks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979ad769",
   "metadata": {},
   "source": [
    "# Business Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3fd3516",
   "metadata": {},
   "source": [
    "The business problem is a radiologist who wants to double-check their work with a model that classifies x-rays as Pneumonia or normal.  The practice has supplied us with their x-rays that they have classified and has asked us to build a model which they can refer to on difficult to classify images. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9aad44e",
   "metadata": {},
   "source": [
    "# Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a0b042",
   "metadata": {},
   "source": [
    "The data consists of 5,856 chest x-ray images. Each image is labelled as either normal or pneumonia.  25% of the images are labelled normal and 75% pneumonia.  The [data]('./data/archive/chest_xray/') comes from an x-ray imaging lab. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f47dd35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b49c226a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "945e9892",
   "metadata": {},
   "outputs": [],
   "source": [
    "#i=Path('./data/archive/chest_xray/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c5ff077",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import array_to_img, img_to_array, load_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b29a1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717d21cf",
   "metadata": {},
   "source": [
    "Loading and converting data to array format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfa0708e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data uploading\n",
    "#train_data_dir = i\n",
    "\n",
    "#Get all the data in the directory data/train, and reshape them\n",
    "#train_generator = ImageDataGenerator().flow_from_directory(\n",
    " #train_data_dir, \n",
    "   #target_size=(64, 64), batch_size=5216, color_mode = \"grayscale\")\n",
    "\n",
    "#Create the datasets\n",
    "#train_images, train_labels = next(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b100187",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data uploading\n",
    "\n",
    "\n",
    "#Directory path\n",
    "#val_data_dir = './data/archive/chest_xray/val'\n",
    "#test_data_dir = './data/archive/chest_xray/test'\n",
    "\n",
    "#Get all the data in the directory data/train (790 images), and reshape them\n",
    "#val_generator = ImageDataGenerator().flow_from_directory(\n",
    "        #val_data_dir, \n",
    "        #target_size=(64, 64), batch_size= 16, color_mode = \"grayscale\")\n",
    "\n",
    "#Get all the data in the directory data/validation (132 images), and reshape them\n",
    "#test_generator = ImageDataGenerator().flow_from_directory(\n",
    "        #test_data_dir, \n",
    "        #target_size=(64, 64), batch_size=234+390, color_mode = \"grayscale\")\n",
    "\n",
    "\n",
    "#Create the datasets\n",
    "#val_images, val_labels = next(val_generator)\n",
    "#test_images, test_labels = next(test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7581df4a",
   "metadata": {},
   "source": [
    "Pickling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94911bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc338a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d892b800",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('train_images.pickle', 'wb') as f:\n",
    "    #pickle.dump(train_images, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f6a5720",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('train_labels.pickle', 'wb') as f:\n",
    "    #pickle.dump(train_labels, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2b45cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('test_images.pickle', 'wb') as f:\n",
    "    #pickle.dump(test_images, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "157ea59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('test_labels.pickle', 'wb') as f:\n",
    "    #pickle.dump(test_labels, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e714122d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('val_images.pickle', 'wb') as f:\n",
    "    #pickle.dump(val_images, f)\n",
    "\n",
    "    \n",
    "#with open('val_labels.pickle', 'wb') as f:\n",
    "    #pickle.dump(val_labels, f)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ffb038",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0ab18ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_images.pickle', 'rb') as g:\n",
    "    train_images= pickle.load(g)\n",
    "with open('test_images.pickle', 'rb') as f:\n",
    "    test_images= pickle.load(f)\n",
    "with open('val_images.pickle', 'rb') as f:\n",
    "    val_images= pickle.load(f)\n",
    "    \n",
    "with open('train_labels.pickle', 'rb') as f:\n",
    "    train_labels= pickle.load(f)\n",
    "with open('test_labels.pickle', 'rb') as f:\n",
    "    test_labels= pickle.load(f)\n",
    "with open('val_labels.pickle', 'rb') as f:\n",
    "    val_labels= pickle.load(f)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4768aef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1583., 4273.], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(train_labels)+ sum(test_labels)+sum(val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65688f2",
   "metadata": {},
   "source": [
    "Class distribution is 1583 to 4273, i.e. 27% and 73%, normal and pneumonia.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a81bf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#array_to_image()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abf49c2",
   "metadata": {},
   "source": [
    "### Example "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e445bf",
   "metadata": {},
   "source": [
    "![scan](./Images/scan.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c70c0d",
   "metadata": {},
   "source": [
    "Combining data from train and test files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bfae61c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.append(train_images, test_images, axis=0)\n",
    "t1 = np.append(train_labels, test_labels, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f3916ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfea732",
   "metadata": {},
   "source": [
    "Splitting combined data into training and test groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c8d21b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, test_images, train_labels, test_labels = train_test_split(t, t1, test_size = .25, random_state =5) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bd78d5",
   "metadata": {},
   "source": [
    "Reshaping data for modelling purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "47ce2685",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = np.reshape(test_images, (np.shape(test_images)[0],64*64))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "188f4346",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = np.reshape(train_images, (np.shape(train_images)[0],64*64))\n",
    "np.shape(train_images)\n",
    "\n",
    "val_images = np.reshape(val_images, (np.shape(val_images)[0],64*64))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f663986",
   "metadata": {},
   "source": [
    "Removing extra column from labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "634bfccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels= train_labels[:,0]\n",
    "val_labels= val_labels[:,0]\n",
    "test_labels= test_labels[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ffab15",
   "metadata": {},
   "source": [
    "Standardizing image data by diving by the maximum pixel value of 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "419588c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images=train_images/255\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "93ee940e",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_images=val_images/255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f83fa1a",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6f93439e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "780d7e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063cb0f7",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c889b3d5",
   "metadata": {},
   "source": [
    "Building initial model, a neural network with 1 hidden layer, with 64 neurons.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4d70db8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(64, input_shape = (4096,), activation = 'tanh'))\n",
    "model.add(tf.keras.layers.Dense(1, activation = 'sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ec1047c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'sgd', loss =  'mse', metrics = ['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0b437a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "69/69 [==============================] - 1s 6ms/step - loss: 0.1721 - acc: 0.7400 - val_loss: 0.2160 - val_acc: 0.6875\n",
      "Epoch 2/15\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 0.1381 - acc: 0.8139 - val_loss: 0.2134 - val_acc: 0.6875\n",
      "Epoch 3/15\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 0.1203 - acc: 0.8578 - val_loss: 0.2103 - val_acc: 0.6875\n",
      "Epoch 4/15\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 0.1097 - acc: 0.8664 - val_loss: 0.1994 - val_acc: 0.6875\n",
      "Epoch 5/15\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 0.0997 - acc: 0.8815 - val_loss: 0.1477 - val_acc: 0.8125\n",
      "Epoch 6/15\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 0.0955 - acc: 0.8911 - val_loss: 0.1400 - val_acc: 0.8125\n",
      "Epoch 7/15\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0921 - acc: 0.8904 - val_loss: 0.1330 - val_acc: 0.8750\n",
      "Epoch 8/15\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 0.0890 - acc: 0.8950 - val_loss: 0.1952 - val_acc: 0.6875\n",
      "Epoch 9/15\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0857 - acc: 0.9000 - val_loss: 0.2157 - val_acc: 0.6250\n",
      "Epoch 10/15\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 0.0856 - acc: 0.8989 - val_loss: 0.1586 - val_acc: 0.7500\n",
      "Epoch 11/15\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0823 - acc: 0.9039 - val_loss: 0.1399 - val_acc: 0.8125\n",
      "Epoch 12/15\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0817 - acc: 0.9002 - val_loss: 0.1759 - val_acc: 0.6875\n",
      "Epoch 13/15\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0799 - acc: 0.9037 - val_loss: 0.1221 - val_acc: 0.8750\n",
      "Epoch 14/15\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0795 - acc: 0.9032 - val_loss: 0.1218 - val_acc: 0.8750\n",
      "Epoch 15/15\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0781 - acc: 0.9050 - val_loss: 0.1124 - val_acc: 0.8750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x290bdc373a0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images,train_labels, batch_size=64, epochs=15, validation_data =(val_images,val_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "13b8a4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model.pickle', 'wb') as f:\n",
    "    pickle.dump(model, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c351b0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model.pickle', 'rb') as g:\n",
    "    model= pickle.load(g)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469f4df0",
   "metadata": {},
   "source": [
    "88% and 90% validation and training accuracies, suggests possible overfitting. Next model reduces the complexity of the model in order to reduce overfitting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93ab6bb",
   "metadata": {},
   "source": [
    "Builing 1a model with 32 neurons and same tanh activation function.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "78f41b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model1a = tf.keras.Sequential()\n",
    "#model1a.add(tf.keras.layers.Dense(32, input_shape = (4096,), activation = 'tanh'))\n",
    "\n",
    "#model1a.add(tf.keras.layers.Dense(1, activation = 'sigmoid'))\n",
    "#model.add(tf.keras.layers.Activation('relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "59faca2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model1a.compile(optimizer = 'sgd', loss =  'mse', metrics = ['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "415407dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "69/69 [==============================] - 1s 4ms/step - loss: 0.1683 - acc: 0.7607 - val_loss: 0.2291 - val_acc: 0.5625\n",
      "Epoch 2/15\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 0.1341 - acc: 0.8256 - val_loss: 0.1889 - val_acc: 0.8125\n",
      "Epoch 3/15\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 0.1181 - acc: 0.8498 - val_loss: 0.1980 - val_acc: 0.6875\n",
      "Epoch 4/15\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 0.1052 - acc: 0.8705 - val_loss: 0.2615 - val_acc: 0.5625\n",
      "Epoch 5/15\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 0.1005 - acc: 0.8753 - val_loss: 0.2164 - val_acc: 0.6875\n",
      "Epoch 6/15\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 0.0941 - acc: 0.8868 - val_loss: 0.1378 - val_acc: 0.8750\n",
      "Epoch 7/15\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 0.0914 - acc: 0.8865 - val_loss: 0.1572 - val_acc: 0.8125\n",
      "Epoch 8/15\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 0.0881 - acc: 0.8936 - val_loss: 0.1335 - val_acc: 0.8750\n",
      "Epoch 9/15\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 0.0849 - acc: 0.8979 - val_loss: 0.1420 - val_acc: 0.8750\n",
      "Epoch 10/15\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 0.0826 - acc: 0.9021 - val_loss: 0.1541 - val_acc: 0.8125\n",
      "Epoch 11/15\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 0.0818 - acc: 0.9016 - val_loss: 0.1368 - val_acc: 0.8750\n",
      "Epoch 12/15\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 0.0793 - acc: 0.9057 - val_loss: 0.1446 - val_acc: 0.8125\n",
      "Epoch 13/15\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 0.0785 - acc: 0.9094 - val_loss: 0.1091 - val_acc: 0.8750\n",
      "Epoch 14/15\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 0.0783 - acc: 0.9062 - val_loss: 0.1636 - val_acc: 0.7500\n",
      "Epoch 15/15\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 0.0781 - acc: 0.9062 - val_loss: 0.1547 - val_acc: 0.8125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x290bdf006d0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model1a.fit(train_images,train_labels, batch_size=64, epochs=15, validation_data =(val_images,val_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "53dba735",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('model1a.pickle', 'wb') as f:\n",
    " #   pickle.dump(model1a, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "01336d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('model1a.pickle', 'rb') as g:\n",
    " #   model1a= pickle.load(g)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1897a3e2",
   "metadata": {},
   "source": [
    "Same training acc of 90% but val acc hovering lower at 80% (88% in baseline), suggests that overfitting not solved. Next model increases the complexity of the model in order to increase accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a6d539",
   "metadata": {},
   "source": [
    "Builing second model by adding to baseline an additional layer with 32 neurons and same tanh activation function.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091b3008",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "672e58e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = tf.keras.Sequential()\n",
    "model2.add(tf.keras.layers.Dense(64, input_shape = (4096,), activation = 'tanh'))\n",
    "model2.add(tf.keras.layers.Dense(32, activation = 'tanh'))\n",
    "model2.add(tf.keras.layers.Dense(1, activation = 'sigmoid'))\n",
    "#model.add(tf.keras.layers.Activation('relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "39151cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(optimizer = 'sgd', loss =  'mse', metrics = ['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "094710f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "69/69 [==============================] - 1s 5ms/step - loss: 0.1676 - acc: 0.7596 - val_loss: 0.3356 - val_acc: 0.5000\n",
      "Epoch 2/15\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 0.1313 - acc: 0.8301 - val_loss: 0.1678 - val_acc: 0.8750\n",
      "Epoch 3/15\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.1130 - acc: 0.8537 - val_loss: 0.1628 - val_acc: 0.8125\n",
      "Epoch 4/15\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 0.1044 - acc: 0.8669 - val_loss: 0.2877 - val_acc: 0.6250\n",
      "Epoch 5/15\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0955 - acc: 0.8806 - val_loss: 0.2900 - val_acc: 0.5625\n",
      "Epoch 6/15\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0888 - acc: 0.8897 - val_loss: 0.1573 - val_acc: 0.7500\n",
      "Epoch 7/15\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0875 - acc: 0.8888 - val_loss: 0.1383 - val_acc: 0.8750\n",
      "Epoch 8/15\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 0.0887 - acc: 0.8849 - val_loss: 0.1090 - val_acc: 0.8750\n",
      "Epoch 9/15\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 0.0841 - acc: 0.8943 - val_loss: 0.2939 - val_acc: 0.5625\n",
      "Epoch 10/15\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 0.0808 - acc: 0.9005 - val_loss: 0.1055 - val_acc: 0.8750\n",
      "Epoch 11/15\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0800 - acc: 0.9030 - val_loss: 0.1564 - val_acc: 0.7500\n",
      "Epoch 12/15\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 0.0784 - acc: 0.9048 - val_loss: 0.0943 - val_acc: 0.8750\n",
      "Epoch 13/15\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 0.0767 - acc: 0.9046 - val_loss: 0.0940 - val_acc: 0.8750\n",
      "Epoch 14/15\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 0.0778 - acc: 0.8989 - val_loss: 0.0863 - val_acc: 0.9375\n",
      "Epoch 15/15\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 0.0736 - acc: 0.9075 - val_loss: 0.1023 - val_acc: 0.8750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x290be2a3a60>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(train_images,train_labels, batch_size=64, epochs=15, validation_data =(val_images,val_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "018515d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model2.pickle', 'wb') as f:\n",
    "    pickle.dump(model2, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aa4e7e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model2.pickle', 'rb') as g:\n",
    "    model2= pickle.load(g)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c7d654",
   "metadata": {},
   "source": [
    "Model 2 training accuracy is improved from prior to 90% but, constant from baseline. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257787ed",
   "metadata": {},
   "source": [
    "Building third model by increasing the learning rate of the optimizer from default .001 to .05 in order to try to increase accuracy.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf5e1b8",
   "metadata": {},
   "source": [
    "Use same layers as model2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "767f7deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.SGD(learning_rate = .05)\n",
    "model3 = tf.keras.Sequential()\n",
    "model3.add(tf.keras.layers.Dense(64, input_shape = (4096,), activation = 'tanh'))\n",
    "model3.add(tf.keras.layers.Dense(32, activation = 'tanh'))\n",
    "model3.add(tf.keras.layers.Dense(1, activation = 'sigmoid'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ce118ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(optimizer = opt, loss =  'mse', metrics = ['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9e023111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "69/69 [==============================] - 1s 4ms/step - loss: 0.1960 - acc: 0.7279 - val_loss: 0.2087 - val_acc: 0.7500\n",
      "Epoch 2/15\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.1525 - acc: 0.7927 - val_loss: 0.2582 - val_acc: 0.5625\n",
      "Epoch 3/15\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 0.1258 - acc: 0.8315 - val_loss: 0.3433 - val_acc: 0.5000\n",
      "Epoch 4/15\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.1141 - acc: 0.8466 - val_loss: 0.1563 - val_acc: 0.8125\n",
      "Epoch 5/15\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 0.1023 - acc: 0.8630 - val_loss: 0.1146 - val_acc: 0.8750\n",
      "Epoch 6/15\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0970 - acc: 0.8737 - val_loss: 0.1694 - val_acc: 0.7500\n",
      "Epoch 7/15\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 0.0899 - acc: 0.8801 - val_loss: 0.3008 - val_acc: 0.5625\n",
      "Epoch 8/15\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 0.0910 - acc: 0.8833 - val_loss: 0.1441 - val_acc: 0.8125\n",
      "Epoch 9/15\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0845 - acc: 0.8902 - val_loss: 0.0857 - val_acc: 0.9375\n",
      "Epoch 10/15\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0840 - acc: 0.8902 - val_loss: 0.0834 - val_acc: 0.8750\n",
      "Epoch 11/15\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0813 - acc: 0.8959 - val_loss: 0.0822 - val_acc: 0.8750\n",
      "Epoch 12/15\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 0.0764 - acc: 0.9057 - val_loss: 0.0697 - val_acc: 0.9375\n",
      "Epoch 13/15\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 0.0739 - acc: 0.9084 - val_loss: 0.0702 - val_acc: 0.9375\n",
      "Epoch 14/15\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0763 - acc: 0.9023 - val_loss: 0.0687 - val_acc: 0.9375\n",
      "Epoch 15/15\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.0797 - acc: 0.8957 - val_loss: 0.1700 - val_acc: 0.7500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x290be365040>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(train_images,train_labels, batch_size=64, epochs=15, validation_data =(val_images,val_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "57f8a3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model3.pickle', 'wb') as f:\n",
    "    pickle.dump(model3, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fed2b680",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model3.pickle', 'rb') as g:\n",
    "    model3= pickle.load(g)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8a312d",
   "metadata": {},
   "source": [
    "Appears to be over-learning, minimum loss is overshot. But accuracy is highest with 90% and around 90 % for training and validation respectively. Model 3 has best performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9cc504b",
   "metadata": {},
   "source": [
    "![acctable](./Images/acctable.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da7a4c4",
   "metadata": {},
   "source": [
    "![acctablex](./Images/acctablex.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3093773",
   "metadata": {},
   "source": [
    "Evaluate model 3 on test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "469c3456",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images=test_images/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f0261335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0873 - acc: 0.8856\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08725250512361526, 0.8856164216995239]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd708a5e",
   "metadata": {},
   "source": [
    "Accuracy on test set is 88%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f67b7be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "preds = model3.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fd53e0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat= []\n",
    "for i in preds:\n",
    "    if i<.5:\n",
    "        yhat.append(0)\n",
    "    else:\n",
    "        yhat.append(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "39493afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d04e6bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf = confusion_matrix(test_labels, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e9b65d56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1061,   19],\n",
       "       [ 148,  232]], dtype=int64)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "82cd951c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a0e198b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x290be17dac0>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cmd = ConfusionMatrixDisplay(cnf)\n",
    "cmd=cmd.from_predictions(test_labels, yhat)\n",
    "cmd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd94116b",
   "metadata": {},
   "source": [
    "19 false negatives and 148 false positives out of 1460 predictions. False negatives represent pneumonia x-rays classified as normal and are more harmful than false positives. 1% false negative rate is acceptably low.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a286cb",
   "metadata": {},
   "source": [
    "# Results/Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ed37f0",
   "metadata": {},
   "source": [
    "Model3 performed best.  The chosen model's accuracy on the holdout test set was 88%.  This can be compared to guessing based on the sample balance, which would yield 73% accuracy.  The false negative rate was very low at 1%. Thus this model can be used as a check by the radiologist, for instance on x-rays that they are less certain about.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d9f9ad",
   "metadata": {},
   "source": [
    "# Recommendations and Future work\n",
    "- This model can be used as a check by the radiologist, for instance on x-rays that they are less certain about.\n",
    "- The model can be examined to determine the important features and the parts of the image that are most important for helpful insights.\n",
    "\n",
    "### Future work\n",
    "\n",
    "- Use CNN\n",
    "- Alter activation functions`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732eaabd",
   "metadata": {},
   "source": [
    "# Contact information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be4d27b",
   "metadata": {},
   "source": [
    "jmarksk@gmail.com\n",
    "5169963175"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19161025",
   "metadata": {},
   "source": [
    "# Repository Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f1bb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "- Xray.ipynb\n",
    "- README.md\n",
    "- Xray_presentation.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dash-env)",
   "language": "python",
   "name": "dash-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
